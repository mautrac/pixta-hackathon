{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7399335,"sourceType":"datasetVersion","datasetId":4302352},{"sourceId":7399341,"sourceType":"datasetVersion","datasetId":4302357}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\n\nimport torch\nimport torch.nn as nn\nfrom PIL import Image\nfrom torchvision.transforms import v2\nfrom torchvision import transforms\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-19T15:03:40.301716Z","iopub.execute_input":"2024-01-19T15:03:40.302150Z","iopub.status.idle":"2024-01-19T15:03:40.308227Z","shell.execute_reply.started":"2024-01-19T15:03:40.302120Z","shell.execute_reply":"2024-01-19T15:03:40.307157Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"!pip install -q transformers","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:40.356533Z","iopub.execute_input":"2024-01-19T15:03:40.356882Z","iopub.status.idle":"2024-01-19T15:03:52.455561Z","shell.execute_reply.started":"2024-01-19T15:03:40.356854Z","shell.execute_reply":"2024-01-19T15:03:52.454302Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"np_images = np.load(\"/kaggle/input/face-aligned/np_images.npy\")\ndata = pd.read_csv(\"/kaggle/input/face-aligned/labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:52.457953Z","iopub.execute_input":"2024-01-19T15:03:52.458831Z","iopub.status.idle":"2024-01-19T15:03:53.328006Z","shell.execute_reply.started":"2024-01-19T15:03:52.458778Z","shell.execute_reply":"2024-01-19T15:03:53.327017Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = 'cuda:0'\nelse:\n    device = 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.329181Z","iopub.execute_input":"2024-01-19T15:03:53.329491Z","iopub.status.idle":"2024-01-19T15:03:53.335941Z","shell.execute_reply.started":"2024-01-19T15:03:53.329465Z","shell.execute_reply":"2024-01-19T15:03:53.335131Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"np_images.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.337990Z","iopub.execute_input":"2024-01-19T15:03:53.338287Z","iopub.status.idle":"2024-01-19T15:03:53.348204Z","shell.execute_reply.started":"2024-01-19T15:03:53.338256Z","shell.execute_reply":"2024-01-19T15:03:53.347318Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"(15310, 224, 224, 3)"},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.349334Z","iopub.execute_input":"2024-01-19T15:03:53.349629Z","iopub.status.idle":"2024-01-19T15:03:53.370714Z","shell.execute_reply.started":"2024-01-19T15:03:53.349604Z","shell.execute_reply":"2024-01-19T15:03:53.369810Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0       file_name  height  width  \\\n0               0   100013282.jpg    1333   2000   \n1               1   100016175.jpg    1333   2000   \n2               2    10004189.jpg    2000   1333   \n3               3   100104575.jpg    1333   2000   \n4               4   100104600.jpg    2000   1333   \n...           ...             ...     ...    ...   \n15305       15305  image_2713.jpg    1024   1024   \n15306       15306  image_3332.jpg    1024   1024   \n15307       15307  image_6905.jpg    1024   1024   \n15308       15308  image_4080.jpg    1024   1024   \n15309       15309  image_8309.jpg    1024   1024   \n\n                                                    bbox     age       race  \\\n0      [934.0000000000097, 144.82228672769534, 238.24...  20-30s  Caucasian   \n1      [1094.0513571635438, 422.91772295627203, 55.45...  20-30s  Caucasian   \n2      [419.93871061403877, 269.1250391680045, 377.19...  20-30s  Mongoloid   \n3      [1490.6909678848915, 676.0000000000097, 37.553...  20-30s  Caucasian   \n4      [549.169724453414, 92.52040334013152, 306.8821...  20-30s  Caucasian   \n...                                                  ...     ...        ...   \n15305  [244.71717171717162, 176.66666666666654, 587.2...  40-50s  Caucasian   \n15306  [265.6338028169031, 174.2441314553992, 584.727...  Senior  Caucasian   \n15307  [251.3434343434343, 184.7171717171712, 500.535...  20-30s  Caucasian   \n15308  [222.72727272727235, 179.8181818181809, 586.90...     Kid  Caucasian   \n15309  [169.37373737373707, 141.48484848484836, 566.2...    Baby  Caucasian   \n\n         masked   skintone    emotion  gender  \n0      unmasked  mid-light    Neutral    Male  \n1      unmasked      light    Neutral    Male  \n2      unmasked      light  Happiness  Female  \n3      unmasked  mid-light    Neutral    Male  \n4      unmasked  mid-light  Happiness  Female  \n...         ...        ...        ...     ...  \n15305  unmasked  mid-light  Happiness    Male  \n15306  unmasked      light  Happiness  Female  \n15307  unmasked      light    Neutral    Male  \n15308  unmasked      light  Happiness  Female  \n15309  unmasked      light    Neutral  Female  \n\n[15310 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>file_name</th>\n      <th>height</th>\n      <th>width</th>\n      <th>bbox</th>\n      <th>age</th>\n      <th>race</th>\n      <th>masked</th>\n      <th>skintone</th>\n      <th>emotion</th>\n      <th>gender</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>100013282.jpg</td>\n      <td>1333</td>\n      <td>2000</td>\n      <td>[934.0000000000097, 144.82228672769534, 238.24...</td>\n      <td>20-30s</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>mid-light</td>\n      <td>Neutral</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>100016175.jpg</td>\n      <td>1333</td>\n      <td>2000</td>\n      <td>[1094.0513571635438, 422.91772295627203, 55.45...</td>\n      <td>20-30s</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>light</td>\n      <td>Neutral</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>10004189.jpg</td>\n      <td>2000</td>\n      <td>1333</td>\n      <td>[419.93871061403877, 269.1250391680045, 377.19...</td>\n      <td>20-30s</td>\n      <td>Mongoloid</td>\n      <td>unmasked</td>\n      <td>light</td>\n      <td>Happiness</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>100104575.jpg</td>\n      <td>1333</td>\n      <td>2000</td>\n      <td>[1490.6909678848915, 676.0000000000097, 37.553...</td>\n      <td>20-30s</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>mid-light</td>\n      <td>Neutral</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>100104600.jpg</td>\n      <td>2000</td>\n      <td>1333</td>\n      <td>[549.169724453414, 92.52040334013152, 306.8821...</td>\n      <td>20-30s</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>mid-light</td>\n      <td>Happiness</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15305</th>\n      <td>15305</td>\n      <td>image_2713.jpg</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>[244.71717171717162, 176.66666666666654, 587.2...</td>\n      <td>40-50s</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>mid-light</td>\n      <td>Happiness</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>15306</th>\n      <td>15306</td>\n      <td>image_3332.jpg</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>[265.6338028169031, 174.2441314553992, 584.727...</td>\n      <td>Senior</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>light</td>\n      <td>Happiness</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>15307</th>\n      <td>15307</td>\n      <td>image_6905.jpg</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>[251.3434343434343, 184.7171717171712, 500.535...</td>\n      <td>20-30s</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>light</td>\n      <td>Neutral</td>\n      <td>Male</td>\n    </tr>\n    <tr>\n      <th>15308</th>\n      <td>15308</td>\n      <td>image_4080.jpg</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>[222.72727272727235, 179.8181818181809, 586.90...</td>\n      <td>Kid</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>light</td>\n      <td>Happiness</td>\n      <td>Female</td>\n    </tr>\n    <tr>\n      <th>15309</th>\n      <td>15309</td>\n      <td>image_8309.jpg</td>\n      <td>1024</td>\n      <td>1024</td>\n      <td>[169.37373737373707, 141.48484848484836, 566.2...</td>\n      <td>Baby</td>\n      <td>Caucasian</td>\n      <td>unmasked</td>\n      <td>light</td>\n      <td>Neutral</td>\n      <td>Female</td>\n    </tr>\n  </tbody>\n</table>\n<p>15310 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"weights = []\ncols = data.columns\nfor col in cols[5:]:\n    print(col)\n    temp = data[col].value_counts()\n    print(temp)\n    n = np.sum(temp)\n    #temp = temp / n\n    #temp = np.exp(temp)\n    weights.append(temp)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.372242Z","iopub.execute_input":"2024-01-19T15:03:53.372605Z","iopub.status.idle":"2024-01-19T15:03:53.395800Z","shell.execute_reply.started":"2024-01-19T15:03:53.372572Z","shell.execute_reply":"2024-01-19T15:03:53.394889Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"age\nage\n20-30s      11236\n40-50s       1602\nKid           954\nSenior        637\nTeenager      536\nBaby          345\nName: count, dtype: int64\nrace\nrace\nMongoloid    7487\nCaucasian    7106\nNegroid       717\nName: count, dtype: int64\nmasked\nmasked\nunmasked    14806\nmasked        504\nName: count, dtype: int64\nskintone\nskintone\nlight        10485\nmid-light     3688\nmid-dark       798\ndark           339\nName: count, dtype: int64\nemotion\nemotion\nHappiness    9218\nNeutral      4844\nSadness       380\nAnger         319\nSurprise      303\nDisgust       132\nFear          114\nName: count, dtype: int64\ngender\ngender\nFemale    10522\nMale       4788\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"labels_set = {}\nfor col in cols[5:]:\n    temp = data[col].unique()\n    labels_set[col] = temp\n    \nlabels_set['age'] = ['Baby', 'Kid', 'Teenager', '20-30s', '40-50s', 'Senior']\nprint(labels_set)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.396925Z","iopub.execute_input":"2024-01-19T15:03:53.397227Z","iopub.status.idle":"2024-01-19T15:03:53.414027Z","shell.execute_reply.started":"2024-01-19T15:03:53.397200Z","shell.execute_reply":"2024-01-19T15:03:53.413142Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"{'age': ['Baby', 'Kid', 'Teenager', '20-30s', '40-50s', 'Senior'], 'race': array(['Caucasian', 'Mongoloid', 'Negroid'], dtype=object), 'masked': array(['unmasked', 'masked'], dtype=object), 'skintone': array(['mid-light', 'light', 'mid-dark', 'dark'], dtype=object), 'emotion': array(['Neutral', 'Happiness', 'Anger', 'Surprise', 'Fear', 'Sadness',\n       'Disgust'], dtype=object), 'gender': array(['Male', 'Female'], dtype=object)}\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn import preprocessing\n\nlabels = dict()\nlabels_dec = dict()\nfor col in cols[5:]:\n    le = preprocessing.LabelEncoder()\n    enc = le.fit_transform(data[col])\n    print(enc)\n    labels[col] = enc\n    labels_dec[col] = le.classes_[enc]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.415460Z","iopub.execute_input":"2024-01-19T15:03:53.416125Z","iopub.status.idle":"2024-01-19T15:03:53.447114Z","shell.execute_reply.started":"2024-01-19T15:03:53.416090Z","shell.execute_reply":"2024-01-19T15:03:53.446155Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"[0 0 0 ... 0 3 2]\n[0 0 1 ... 0 0 0]\n[1 1 1 ... 1 1 1]\n[3 1 1 ... 1 1 1]\n[4 4 3 ... 4 3 4]\n[1 1 0 ... 1 0 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Edit thuộc tính train**","metadata":{}},{"cell_type":"code","source":"feature = 'emotion'","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.448325Z","iopub.execute_input":"2024-01-19T15:03:53.448656Z","iopub.status.idle":"2024-01-19T15:03:53.455974Z","shell.execute_reply.started":"2024-01-19T15:03:53.448628Z","shell.execute_reply":"2024-01-19T15:03:53.455190Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"labels_dec","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.460080Z","iopub.execute_input":"2024-01-19T15:03:53.460384Z","iopub.status.idle":"2024-01-19T15:03:53.467610Z","shell.execute_reply.started":"2024-01-19T15:03:53.460333Z","shell.execute_reply":"2024-01-19T15:03:53.466854Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'age': array(['20-30s', '20-30s', '20-30s', ..., '20-30s', 'Kid', 'Baby'],\n       dtype=object),\n 'race': array(['Caucasian', 'Caucasian', 'Mongoloid', ..., 'Caucasian',\n        'Caucasian', 'Caucasian'], dtype=object),\n 'masked': array(['unmasked', 'unmasked', 'unmasked', ..., 'unmasked', 'unmasked',\n        'unmasked'], dtype=object),\n 'skintone': array(['mid-light', 'light', 'light', ..., 'light', 'light', 'light'],\n       dtype=object),\n 'emotion': array(['Neutral', 'Neutral', 'Happiness', ..., 'Neutral', 'Happiness',\n        'Neutral'], dtype=object),\n 'gender': array(['Male', 'Male', 'Female', ..., 'Male', 'Female', 'Female'],\n       dtype=object)}"},"metadata":{}}]},{"cell_type":"code","source":"labels_set","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.468890Z","iopub.execute_input":"2024-01-19T15:03:53.469257Z","iopub.status.idle":"2024-01-19T15:03:53.479529Z","shell.execute_reply.started":"2024-01-19T15:03:53.469232Z","shell.execute_reply":"2024-01-19T15:03:53.478663Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"{'age': ['Baby', 'Kid', 'Teenager', '20-30s', '40-50s', 'Senior'],\n 'race': array(['Caucasian', 'Mongoloid', 'Negroid'], dtype=object),\n 'masked': array(['unmasked', 'masked'], dtype=object),\n 'skintone': array(['mid-light', 'light', 'mid-dark', 'dark'], dtype=object),\n 'emotion': array(['Neutral', 'Happiness', 'Anger', 'Surprise', 'Fear', 'Sadness',\n        'Disgust'], dtype=object),\n 'gender': array(['Male', 'Female'], dtype=object)}"},"metadata":{}}]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.480849Z","iopub.execute_input":"2024-01-19T15:03:53.481299Z","iopub.status.idle":"2024-01-19T15:03:53.490945Z","shell.execute_reply.started":"2024-01-19T15:03:53.481257Z","shell.execute_reply":"2024-01-19T15:03:53.490015Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"{'age': array([0, 0, 0, ..., 0, 3, 2]),\n 'race': array([0, 0, 1, ..., 0, 0, 0]),\n 'masked': array([1, 1, 1, ..., 1, 1, 1]),\n 'skintone': array([3, 1, 1, ..., 1, 1, 1]),\n 'emotion': array([4, 4, 3, ..., 4, 3, 4]),\n 'gender': array([1, 1, 0, ..., 1, 0, 0])}"},"metadata":{}}]},{"cell_type":"code","source":"labels[feature]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.492037Z","iopub.execute_input":"2024-01-19T15:03:53.492314Z","iopub.status.idle":"2024-01-19T15:03:53.501069Z","shell.execute_reply.started":"2024-01-19T15:03:53.492282Z","shell.execute_reply":"2024-01-19T15:03:53.500181Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"array([4, 4, 3, ..., 4, 3, 4])"},"metadata":{}}]},{"cell_type":"code","source":"mytransform = transforms.Compose([\n            #transforms.RandomHorizontalFlip(),\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),  # mmb\n        ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.502208Z","iopub.execute_input":"2024-01-19T15:03:53.502487Z","iopub.status.idle":"2024-01-19T15:03:53.510069Z","shell.execute_reply.started":"2024-01-19T15:03:53.502463Z","shell.execute_reply":"2024-01-19T15:03:53.509268Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = Image.fromarray((self.image_paths[idx]).astype(np.uint8)).convert('RGB')\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        label = torch.tensor(label)\n\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.511142Z","iopub.execute_input":"2024-01-19T15:03:53.511513Z","iopub.status.idle":"2024-01-19T15:03:53.520295Z","shell.execute_reply.started":"2024-01-19T15:03:53.511488Z","shell.execute_reply":"2024-01-19T15:03:53.519385Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"dataset = CustomImageDataset(image_paths=np_images, labels=labels[feature], transform=mytransform)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.521364Z","iopub.execute_input":"2024-01-19T15:03:53.521631Z","iopub.status.idle":"2024-01-19T15:03:53.532482Z","shell.execute_reply.started":"2024-01-19T15:03:53.521608Z","shell.execute_reply":"2024-01-19T15:03:53.531530Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.533825Z","iopub.execute_input":"2024-01-19T15:03:53.534421Z","iopub.status.idle":"2024-01-19T15:03:53.547290Z","shell.execute_reply.started":"2024-01-19T15:03:53.534388Z","shell.execute_reply":"2024-01-19T15:03:53.546300Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"(tensor([[[0.0627, 0.0627, 0.0627,  ..., 0.3569, 0.3647, 0.3647],\n          [0.0627, 0.0627, 0.0627,  ..., 0.3647, 0.3569, 0.3686],\n          [0.0627, 0.0627, 0.0627,  ..., 0.3647, 0.3529, 0.3647],\n          ...,\n          [0.2392, 0.2706, 0.2902,  ..., 0.8118, 0.8118, 0.8118],\n          [0.2353, 0.2745, 0.2941,  ..., 0.8157, 0.8118, 0.8118],\n          [0.2431, 0.2627, 0.2863,  ..., 0.8118, 0.8196, 0.8157]],\n \n         [[0.0627, 0.0627, 0.0627,  ..., 0.3059, 0.3020, 0.3020],\n          [0.0627, 0.0627, 0.0627,  ..., 0.3137, 0.3020, 0.3020],\n          [0.0627, 0.0627, 0.0627,  ..., 0.3137, 0.3020, 0.3020],\n          ...,\n          [0.1490, 0.1686, 0.1843,  ..., 0.7020, 0.6980, 0.6980],\n          [0.1451, 0.1686, 0.1882,  ..., 0.6980, 0.6980, 0.6941],\n          [0.1451, 0.1608, 0.1765,  ..., 0.6941, 0.6980, 0.6980]],\n \n         [[0.0627, 0.0627, 0.0627,  ..., 0.2392, 0.2392, 0.2392],\n          [0.0627, 0.0627, 0.0627,  ..., 0.2471, 0.2353, 0.2392],\n          [0.0627, 0.0627, 0.0627,  ..., 0.2471, 0.2353, 0.2392],\n          ...,\n          [0.0941, 0.1020, 0.1020,  ..., 0.5922, 0.5961, 0.5961],\n          [0.0863, 0.0941, 0.1098,  ..., 0.5882, 0.5882, 0.5843],\n          [0.0941, 0.0980, 0.1020,  ..., 0.5843, 0.5882, 0.5882]]]),\n tensor(4))"},"metadata":{}}]},{"cell_type":"code","source":"id2label = dict(zip(labels[feature], labels_dec[feature]))\nlabel2id = {labels[feature]: i for i, labels[feature] in id2label.items()}","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.548459Z","iopub.execute_input":"2024-01-19T15:03:53.548755Z","iopub.status.idle":"2024-01-19T15:03:53.557959Z","shell.execute_reply.started":"2024-01-19T15:03:53.548731Z","shell.execute_reply":"2024-01-19T15:03:53.556892Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"id2label","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.559093Z","iopub.execute_input":"2024-01-19T15:03:53.559364Z","iopub.status.idle":"2024-01-19T15:03:53.569770Z","shell.execute_reply.started":"2024-01-19T15:03:53.559341Z","shell.execute_reply":"2024-01-19T15:03:53.568953Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"{4: 'Neutral',\n 3: 'Happiness',\n 0: 'Anger',\n 6: 'Surprise',\n 2: 'Fear',\n 5: 'Sadness',\n 1: 'Disgust'}"},"metadata":{}}]},{"cell_type":"code","source":"label2id","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.570826Z","iopub.execute_input":"2024-01-19T15:03:53.571098Z","iopub.status.idle":"2024-01-19T15:03:53.581722Z","shell.execute_reply.started":"2024-01-19T15:03:53.571075Z","shell.execute_reply":"2024-01-19T15:03:53.580965Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"{'Neutral': 4,\n 'Happiness': 3,\n 'Anger': 0,\n 'Surprise': 6,\n 'Fear': 2,\n 'Sadness': 5,\n 'Disgust': 1}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nfrom transformers import ViTForImageClassification, ViTFeatureExtractor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\ndef train(model, dataloader, optimizer, criterion, device):\n    model.train()\n    running_loss = 0.0\n\n    for images, labels in tqdm(dataloader, desc=\"Training\"):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(images)\n        loss = criterion(outputs.logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    return running_loss / len(dataloader)\n\ndef evaluate(model, dataloader, device):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for images, labels in tqdm(dataloader, desc=\"Evaluating\"):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.582940Z","iopub.execute_input":"2024-01-19T15:03:53.583631Z","iopub.status.idle":"2024-01-19T15:03:53.594329Z","shell.execute_reply.started":"2024-01-19T15:03:53.583596Z","shell.execute_reply":"2024-01-19T15:03:53.593390Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Chia dữ liệu thành tập huấn luyện và tập kiểm thử\ntrain_size = 0.8\ntrain_dataset, test_dataset = train_test_split(dataset, train_size=train_size, stratify=labels_dec[feature], random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:03:53.595332Z","iopub.execute_input":"2024-01-19T15:03:53.595716Z","iopub.status.idle":"2024-01-19T15:04:04.238503Z","shell.execute_reply.started":"2024-01-19T15:03:53.595683Z","shell.execute_reply":"2024-01-19T15:04:04.237497Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"len(set(labels_set[feature]))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:04.239928Z","iopub.execute_input":"2024-01-19T15:04:04.240662Z","iopub.status.idle":"2024-01-19T15:04:04.248490Z","shell.execute_reply.started":"2024-01-19T15:04:04.240616Z","shell.execute_reply":"2024-01-19T15:04:04.247542Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"7"},"metadata":{}}]},{"cell_type":"code","source":"batch_size = 16\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\nmodel_name = 'google/vit-base-patch16-224-in21k'\nmodel = ViTForImageClassification.from_pretrained(model_name, num_labels=len(set(labels_set[feature])))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\ncriterion = torch.nn.CrossEntropyLoss()\n\nepochs = 10\nfor epoch in range(epochs):\n    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n    accuracy = evaluate(model, test_dataloader, device)\n\n    print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss:.4f} - Test Accuracy: {accuracy:.4f}\")\n    path = f'/kaggle/working/model_{feature}_{epoch+1}.pth'\n    torch.save(model, path)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:04:04.249700Z","iopub.execute_input":"2024-01-19T15:04:04.250244Z","iopub.status.idle":"2024-01-19T15:47:01.565164Z","shell.execute_reply.started":"2024-01-19T15:04:04.250209Z","shell.execute_reply":"2024-01-19T15:47:01.564144Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nTraining: 100%|██████████| 766/766 [03:54<00:00,  3.26it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  8.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - Train Loss: 0.5775 - Test Accuracy: 0.8367\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:55<00:00,  3.25it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  9.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10 - Train Loss: 0.4129 - Test Accuracy: 0.8338\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:55<00:00,  3.25it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  8.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10 - Train Loss: 0.3005 - Test Accuracy: 0.8387\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:55<00:00,  3.25it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  9.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10 - Train Loss: 0.1972 - Test Accuracy: 0.8272\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:55<00:00,  3.25it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  8.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10 - Train Loss: 0.1454 - Test Accuracy: 0.8383\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:55<00:00,  3.25it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  8.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10 - Train Loss: 0.1036 - Test Accuracy: 0.8390\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:55<00:00,  3.25it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  8.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10 - Train Loss: 0.0774 - Test Accuracy: 0.8357\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:55<00:00,  3.25it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  8.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8/10 - Train Loss: 0.0597 - Test Accuracy: 0.8194\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:55<00:00,  3.25it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  9.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9/10 - Train Loss: 0.0578 - Test Accuracy: 0.8374\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 766/766 [03:54<00:00,  3.26it/s]\nEvaluating: 100%|██████████| 192/192 [00:21<00:00,  9.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10/10 - Train Loss: 0.0525 - Test Accuracy: 0.8367\n","output_type":"stream"}]},{"cell_type":"code","source":"path = f'/kaggle/working/model_{feature}.pth'\ntorch.save(model, path)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:01.566786Z","iopub.execute_input":"2024-01-19T15:47:01.567096Z","iopub.status.idle":"2024-01-19T15:47:02.083883Z","shell.execute_reply.started":"2024-01-19T15:47:01.567067Z","shell.execute_reply":"2024-01-19T15:47:02.082847Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# img_test = Image.open('/kaggle/input/fac-data-crop/output_images/img_10226.jpg')","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:02.086061Z","iopub.execute_input":"2024-01-19T15:47:02.086954Z","iopub.status.idle":"2024-01-19T15:47:02.092901Z","shell.execute_reply.started":"2024-01-19T15:47:02.086908Z","shell.execute_reply":"2024-01-19T15:47:02.091823Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# img_test","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:02.094329Z","iopub.execute_input":"2024-01-19T15:47:02.095727Z","iopub.status.idle":"2024-01-19T15:47:02.102379Z","shell.execute_reply.started":"2024-01-19T15:47:02.095685Z","shell.execute_reply":"2024-01-19T15:47:02.101494Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# img_test = mytransform(img_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:02.109609Z","iopub.execute_input":"2024-01-19T15:47:02.110052Z","iopub.status.idle":"2024-01-19T15:47:02.115203Z","shell.execute_reply.started":"2024-01-19T15:47:02.110027Z","shell.execute_reply":"2024-01-19T15:47:02.114231Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# pred = model(img_test.unsqueeze(0).to(device))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:02.116368Z","iopub.execute_input":"2024-01-19T15:47:02.116926Z","iopub.status.idle":"2024-01-19T15:47:02.140107Z","shell.execute_reply.started":"2024-01-19T15:47:02.116901Z","shell.execute_reply":"2024-01-19T15:47:02.138115Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# pred.logits[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:02.141421Z","iopub.execute_input":"2024-01-19T15:47:02.141770Z","iopub.status.idle":"2024-01-19T15:47:02.543711Z","shell.execute_reply.started":"2024-01-19T15:47:02.141723Z","shell.execute_reply":"2024-01-19T15:47:02.542559Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# pred[0].argmax().item()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:02.546126Z","iopub.execute_input":"2024-01-19T15:47:02.546575Z","iopub.status.idle":"2024-01-19T15:47:03.110881Z","shell.execute_reply.started":"2024-01-19T15:47:02.546530Z","shell.execute_reply":"2024-01-19T15:47:03.109876Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"# torch.nn.functional.softmax(pred.logits[0], dim=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:03.112158Z","iopub.execute_input":"2024-01-19T15:47:03.114271Z","iopub.status.idle":"2024-01-19T15:47:03.264814Z","shell.execute_reply.started":"2024-01-19T15:47:03.114235Z","shell.execute_reply":"2024-01-19T15:47:03.263925Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# id2label[pred[0].argmax().item()]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:47:03.266068Z","iopub.execute_input":"2024-01-19T15:47:03.266907Z","iopub.status.idle":"2024-01-19T15:47:03.275338Z","shell.execute_reply.started":"2024-01-19T15:47:03.266871Z","shell.execute_reply":"2024-01-19T15:47:03.274616Z"},"trusted":true},"execution_count":74,"outputs":[]}]}